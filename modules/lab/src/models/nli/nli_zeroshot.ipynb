{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/Projects/vis-desc/modules/lab/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-10-19 20:13:46.122515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760897626.162219  639386 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760897626.186683  639386 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-19 20:13:46.269861: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Iterable\n",
    "from dataclasses import dataclass\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from models.nli.nli_base import NLIZeroshotClassifier\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NLIParams:\n",
    "    candidate_labels: list[str]\n",
    "    hypothesis_template: str\n",
    "    value_getter: Callable[[Iterable[float]], float]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.candidate_labels=} | {self.hypothesis_template=}\"\n",
    "\n",
    "\n",
    "def test_params(\n",
    "    model: NLIZeroshotClassifier, params: NLIParams, texts: list[str], labels: list[str]\n",
    ") -> None:\n",
    "    with model.set_options(\n",
    "        candidate_labels=params.candidate_labels,\n",
    "        hypothesis_template=params.hypothesis_template,\n",
    "    ) as m:\n",
    "        scores = [params.value_getter(score) for score in m.evaluate_segments(texts)]\n",
    "\n",
    "    # Calculate correlation between scores and true labels\n",
    "    correlation, _ = pearsonr(scores, labels)\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from models.nli.nli_roberta import NLIRoberta\n",
    "\n",
    "\n",
    "model = NLIRoberta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d03cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils import DATA_DIR\n",
    "\n",
    "train_set = pd.read_parquet(DATA_DIR / \"datasets\" / \"small\" / \"train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc2abca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.candidate_labels=['detailed', 'not detailed'] | self.hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.6750189928326207\n",
      "self.candidate_labels=['can be easily visualized with specific sensory details', 'is difficult to visualize or abstract'] | self.hypothesis_template='This text {}': 0.19942125667573896\n"
     ]
    }
   ],
   "source": [
    "params_for_comparison = [\n",
    "    NLIParams(\n",
    "        candidate_labels=[\"detailed\", \"not detailed\"],\n",
    "        hypothesis_template=\"This text is {} in terms of visual details of characters, setting, or environment.\",\n",
    "        value_getter=lambda scores: scores[0],\n",
    "    ),\n",
    "    NLIParams(\n",
    "        candidate_labels=[\n",
    "            \"can be easily visualized with specific sensory details\",\n",
    "            \"is difficult to visualize or abstract\",\n",
    "        ],\n",
    "        hypothesis_template=\"This text {}\",\n",
    "        value_getter=lambda scores: scores[0],\n",
    "    ),\n",
    "]\n",
    "\n",
    "correlation = []\n",
    "for params in params_for_comparison:\n",
    "    corr = test_params(\n",
    "        model, params, train_set[\"text\"].tolist(), train_set[\"label\"].tolist()\n",
    "    )\n",
    "    correlation.append(corr)\n",
    "    print(f\"{params}: {corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebf5ec3",
   "metadata": {},
   "source": [
    "### Best\n",
    "\n",
    "microsoft/deberta-base-mnli\n",
    "\n",
    "MoritzLaurer/deberta-v3-base-zeroshot-v2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967aea51",
   "metadata": {},
   "source": [
    "candidate_labels=['visual', 'not visual'], hypothesis_template='This text is {} in terms of sensory details, imagery, characters, environment, and vivid descriptions.': 0.3074255046401304\n",
    "candidate_labels=['visual', 'non_visual'], hypothesis_template='This text is {} in terms of sensory details, imagery, characters, and vivid descriptions of foreground and background.': 0.31445027174020534\n",
    "candidate_labels=['visual', 'non_visual'], hypothesis_template='This text is {} in terms of sensory details, imagery, characters, environment, and vivid descriptions of foreground and background.': 0.32622171646256426\n",
    "candidate_labels=['descriptive', 'non_descriptive'], hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.2955842441890373\n",
    "candidate_labels=['disagree', 'agree', 'strongly agree'], hypothesis_template='I {} that the text is visual in terms of sensory details, imagery, and vivid descriptions.': 0.11353990327893874\n",
    "candidate_labels=['visual', 'non_visual'], hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.20003419028989294\n",
    "candidate_labels=['detailed', 'not_detailed'], hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.38513134801015203\n",
    "candidate_labels=['descriptive', 'non_descriptive'], hypothesis_template='This text is {} in terms of sensory details, imagery, and vivid descriptions.': 0.1388104796342361\n",
    "candidate_labels=['visual', 'non_visual'], hypothesis_template='This text is {} in terms of sensory details, imagery, and vivid descriptions.': 0.3462052985649622\n",
    "candidate_labels=['detailed', 'not_detailed'], hypothesis_template='This text is {} in terms of sensory details, imagery, and vivid descriptions.': 0.2931661821955478\n",
    "\n",
    "self.candidate_labels=['This text contains no visual imagery', 'This text describes a simple object, body part, or animal', 'This text describes a simple object or person in action', 'This text describes a detailed object, place, or identifiable character', 'This text describes a detailed place or character performing an action', 'This text describes a complete scene or detailed face', 'This text describes a complete scene with action or movement', 'This text describes a rich scene with multiple visual elements including character, setting, and details', 'This text describes a rich scene with multiple visual elements and dynamic action', 'This text vividly depicts a full scene with background, foreground, atmospheric details, and time of day'] | self.hypothesis_template='This passage depicts {}': 0.14101946631175694\n",
    "self.candidate_labels=['no visual description', 'a basic visible object or person', 'a basic object or person doing something', 'a detailed location, object, or recognizable character', 'a detailed place or character in motion', 'a scene with face details or minimal setting', 'a scene with setting and action', 'a rich visual scene with character, setting, and descriptive details', 'a rich visual scene with multiple elements in motion', 'a vivid, complete scene with atmosphere, lighting, and layered visual information'] | self.hypothesis_template='The visual richness of this text shows {}': 0.010100976665978988\n",
    "self.candidate_labels=['zero visual imagery', 'minimal visual content - single simple element', 'low visual detail - simple element with action', 'moderate visual content - detailed element or basic character', 'moderate visual scene - setting with action', 'good visual description - complete scene or detailed character', 'rich visual scene - setting with movement and details', 'very rich visual scene - multiple described elements and context', 'vivid dynamic scene - rich setting with action and details', 'fully immersive visual scene - atmospheric, layered, cinematic description'] | self.hypothesis_template='The level of visual description in this text is: {}': 0.15886393925343895\n",
    "\n",
    "self.candidate_labels=['contains vivid visual description with multiple specific details', 'contains minimal or no visual description'] | self.hypothesis_template='This text {}': 0.2468695717544066\n",
    "self.candidate_labels=['describes a visually complete scene with setting and details', 'describes abstract concepts without visual imagery'] | self.hypothesis_template='This text {}': 0.2814456504320367\n",
    "self.candidate_labels=['can be easily visualized with specific sensory details', 'is difficult to visualize or abstract'] | self.hypothesis_template='This text {}': 0.34294634460914136\n",
    "self.candidate_labels=['provides rich visual description of people, places, or objects', 'provides little visual description'] | self.hypothesis_template='This text {}': 0.10715816625655927"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc4cb8",
   "metadata": {},
   "source": [
    "deberta - 5:45\n",
    "candidate_labels=['detailed', 'not_detailed'], hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.38513134801015203\n",
    "self.candidate_labels=['can be easily visualized with specific sensory details', 'is difficult to visualize or abstract'] | self.hypothesis_template='This text {}': 0.34294634460914136\n",
    "\n",
    "bart-large - 11:06\n",
    "candidate_labels=['detailed', 'not_detailed'], hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.350\n",
    "self.candidate_labels=['can be easily visualized with specific sensory details', 'is difficult to visualize or abstract'] | self.hypothesis_template='This text {}': 0.276\n",
    "\n",
    "MoritzLaurer/ModernBERT-large-zeroshot-v2.0 - 18:38\n",
    "candidate_labels=['detailed', 'not_detailed'], hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.486\n",
    "self.candidate_labels=['can be easily visualized with specific sensory details', 'is difficult to visualize or abstract'] | self.hypothesis_template='This text {}': 0.421\n",
    "\n",
    "MoritzLaurer/deberta-v3-large-zeroshot-v2.0 - 21:09\n",
    "self.candidate_labels=['detailed', 'not_detailed'] | self.hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.510\n",
    "self.candidate_labels=['can be easily visualized with specific sensory details', 'is difficult to visualize or abstract'] | self.hypothesis_template='This text {}': 0.387\n",
    "\n",
    "MoritzLaurer/deberta-v3-base-zeroshot-v2.0 8:44\n",
    "self.candidate_labels=['detailed', 'not_detailed'] | self.hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.508 -> 0.496\n",
    "self.candidate_labels=['can be easily visualized with specific sensory details', 'is difficult to visualize or abstract'] | self.hypothesis_template='This text {}': 0.245\n",
    "\n",
    "MoritzLaurer/roberta-large-zeroshot-v2.0-c 16:48\n",
    "self.candidate_labels=['detailed', 'not_detailed'] | self.hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.572 -> 0.578\n",
    "self.candidate_labels=['can be easily visualized with specific sensory details', 'is difficult to visualize or abstract'] | self.hypothesis_template='This text {}': 0.239\n",
    "\n",
    "MoritzLaurer/roberta-base-zeroshot-v2.0-c 21:43\n",
    "self.candidate_labels=['detailed', 'not detailed'] | self.hypothesis_template='This text is {} in terms of visual details of characters, setting, or environment.': 0.6750189928326207\n",
    "self.candidate_labels=['can be easily visualized with specific sensory details', 'is difficult to visualize or abstract'] | self.hypothesis_template='This text {}': 0.19942125667573896"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
