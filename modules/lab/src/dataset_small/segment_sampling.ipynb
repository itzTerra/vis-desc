{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "330ec6f4",
   "metadata": {},
   "source": [
    "### 1. Preprocess and split all books into segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ba8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from book_segmenting import TextSegmenter\n",
    "from book_preprocessing import TxtBookPreprocessor\n",
    "from utils import SEGMENT_DIR, BOOK_DIR\n",
    "\n",
    "SEGMENT_CHARS_MIN = 150\n",
    "SEGMENT_CHARS_MAX = 500\n",
    "segment_dir = SEGMENT_DIR / \"batch2\"\n",
    "\n",
    "preprocessor = TxtBookPreprocessor()\n",
    "segmenter = TextSegmenter(segment_size=(SEGMENT_CHARS_MIN, SEGMENT_CHARS_MAX))\n",
    "\n",
    "for f in segment_dir.glob(\"*.json\"):\n",
    "    f.unlink()\n",
    "for book in BOOK_DIR.glob(\"*.txt\"):\n",
    "    with open(book, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        book_content = f.read()\n",
    "    book_slug = book.stem\n",
    "    chunks = segmenter.segment_text(preprocessor.clean_text(book_content))\n",
    "    with open(segment_dir / f\"{book_slug}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(chunks, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a52c74",
   "metadata": {},
   "source": [
    "### 2. Sample N segments from all unused yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a7857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available: 610668 segments\n",
      "  Science Fiction: only 90 available (wanted 1428)\n",
      "  Fiction: only 603 available (wanted 1428)\n",
      "  Western: only 66 available (wanted 1428)\n",
      "  Fantasy: only 147 available (wanted 1428)\n",
      "  Mystery: only 222 available (wanted 1428)\n",
      "  History: only 57 available (wanted 1428)\n",
      "  Travel: only 15 available (wanted 1428)\n",
      "\n",
      "Saved 10000 segments to /home/terra/Projects/vis-desc/modules/lab/data/to-annotate/batch_10k.json\n",
      "=== CORPUS STATUS ===\n",
      "Books: 400\n",
      "Total segments: 611140\n",
      "Used segments: 500\n",
      "Available: 610640\n",
      "\n",
      "By genre:\n",
      "  Fiction: 315528 (201 books)\n",
      "  Mystery: 106695 (74 books)\n",
      "  Fantasy: 60682 (49 books)\n",
      "  Western: 45875 (22 books)\n",
      "  Science Fiction: 43143 (30 books)\n",
      "  History: 32717 (19 books)\n",
      "  Travel: 6500 (5 books)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils import SEGMENT_DIR, TO_ANNOTATE_DIR, BOOK_META_DIR\n",
    "from dataset_small.segment_sampling import SegmentSampler\n",
    "\n",
    "N = 10000\n",
    "BATCH_NAME = \"batch_10k\"\n",
    "MAX_PER_BOOK = 3\n",
    "SEED = 42\n",
    "segment_dir = SEGMENT_DIR / \"batch2\"\n",
    "\n",
    "sampler = SegmentSampler(segment_dir, BOOK_META_DIR, TO_ANNOTATE_DIR, SEED)\n",
    "sample = sampler.sample_balanced(N, BATCH_NAME, max_per_book=MAX_PER_BOOK)\n",
    "sampler.print_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ccabd",
   "metadata": {},
   "source": [
    "### Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import BOOK_META_DIR, DATA_DIR\n",
    "\n",
    "genre_counts = collections.Counter()\n",
    "for meta_file in BOOK_META_DIR.glob(\"*.json\"):\n",
    "    try:\n",
    "        with open(meta_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        g = data.get(\"genre\") or \"Unknown\"\n",
    "        if isinstance(g, str):\n",
    "            g = g.strip() or \"Unknown\"\n",
    "        else:\n",
    "            g = \"Unknown\"\n",
    "        if g.lower() == \"science fiction\":\n",
    "            g = \"Sci-Fi\"\n",
    "        genre_counts[g] += 1\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if not genre_counts:\n",
    "    print(\"No genre data found for Matplotlib chart.\")\n",
    "else:\n",
    "    genres, counts = zip(*genre_counts.most_common())\n",
    "    total = sum(counts)\n",
    "    plt.rcParams.update({\"font.size\": 42, \"axes.titlesize\": 48, \"legend.fontsize\": 32})\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 14), dpi=120)\n",
    "\n",
    "    def autopct_fmt(pct):\n",
    "        return (\"%0.1f%%\" % pct) if pct >= 1 else \"\"\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        counts,\n",
    "        labels=None,  # legend instead of slice text\n",
    "        autopct=autopct_fmt,\n",
    "        startangle=90,\n",
    "        counterclock=False,\n",
    "        pctdistance=0.70,\n",
    "        textprops={\"color\": \"#111\", \"fontsize\": 44},\n",
    "        wedgeprops={\"linewidth\": 2.5, \"edgecolor\": \"white\"},\n",
    "    )\n",
    "\n",
    "    for t in autotexts:\n",
    "        t.set_fontsize(44)\n",
    "        t.set_fontweight(\"bold\")\n",
    "\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    legend_patches = [\n",
    "        Patch(facecolor=w.get_facecolor(), edgecolor=\"white\", label=f\"{g} ({c})\")\n",
    "        for w, g, c in zip(wedges, genres, counts)\n",
    "    ]\n",
    "\n",
    "    fig.subplots_adjust(left=0, right=0.80, top=1, bottom=0)\n",
    "\n",
    "    leg = fig.legend(\n",
    "        handles=legend_patches,\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(0.7, 0.5),\n",
    "        frameon=True,\n",
    "        title_fontsize=36,\n",
    "        borderpad=0.4,\n",
    "        labelspacing=0.9,\n",
    "        handlelength=1.6,\n",
    "        handleheight=1.1,\n",
    "    )\n",
    "    frame = leg.get_frame()\n",
    "    frame.set_alpha(0.18)\n",
    "    frame.set_edgecolor(\"#bcbcbc\")\n",
    "    frame.set_linewidth(1.2)\n",
    "    frame.set_facecolor(\"#ffffff\")\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    pie_path = DATA_DIR / \"genre_distribution.png\"\n",
    "    fig.savefig(pie_path, bbox_inches=\"tight\", pad_inches=0, transparent=True)\n",
    "    print(\"Saved pie to\", pie_path)\n",
    "    plt.show()\n",
    "    print(\"Total books counted:\", total)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a4d13c",
   "metadata": {},
   "source": [
    "### Small part 2 (prefer new books)\n",
    "\n",
    "sample from new books first, sample from the old ones only after the book/genre limit is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486ec4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only-new books: 110\n",
      "Available new segments: 610668\n",
      "Available old segments: 426190\n",
      "Target total: 500 | Genres: 7 | Per-genre target: 71\n",
      "Available new segments: 610668\n",
      "Available old segments: 426190\n",
      "Target total: 500 | Genres: 7 | Per-genre target: 71\n",
      "  History: shortage (needed 71, got 60)\n",
      "  Travel: shortage (needed 71, got 18)\n",
      "  History: shortage (needed 71, got 60)\n",
      "  Travel: shortage (needed 71, got 18)\n",
      "Saved 500 segments to /home/terra/Projects/vis-desc/modules/lab/data/to-annotate/batch_002.json\n",
      "Sample composition -> New: 150 | Old: 350\n",
      "By genre (sampled):\n",
      "  Fiction: 107\n",
      "  Mystery: 80\n",
      "  Fantasy: 79\n",
      "  Science Fiction: 76\n",
      "  Western: 75\n",
      "  History: 65\n",
      "  Travel: 18\n",
      "Preferential sampling done.\n",
      "Saved 500 segments to /home/terra/Projects/vis-desc/modules/lab/data/to-annotate/batch_002.json\n",
      "Sample composition -> New: 150 | Old: 350\n",
      "By genre (sampled):\n",
      "  Fiction: 107\n",
      "  Mystery: 80\n",
      "  Fantasy: 79\n",
      "  Science Fiction: 76\n",
      "  Western: 75\n",
      "  History: 65\n",
      "  Travel: 18\n",
      "Preferential sampling done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils import SEGMENT_DIR, TO_ANNOTATE_DIR, BOOK_META_DIR\n",
    "from dataset_small.segment_sampling import SegmentSampler\n",
    "\n",
    "NEW_DIR = SEGMENT_DIR / \"batch2\"\n",
    "OLD_DIR = SEGMENT_DIR / \"batch1\"\n",
    "\n",
    "only_new_books = set(f.stem for f in NEW_DIR.glob(\"*.json\")) - set(\n",
    "    f.stem for f in OLD_DIR.glob(\"*.json\")\n",
    ")\n",
    "print(f\"Only-new books: {len(only_new_books)}\")\n",
    "\n",
    "N_PREF = 500\n",
    "BATCH_NAME_PREF = \"batch_002\"\n",
    "MAX_PER_BOOK_PREF = 3\n",
    "SEED = 42\n",
    "\n",
    "new_sampler = SegmentSampler(NEW_DIR, BOOK_META_DIR, TO_ANNOTATE_DIR, SEED)\n",
    "old_sampler = SegmentSampler(OLD_DIR, BOOK_META_DIR, TO_ANNOTATE_DIR, SEED)\n",
    "\n",
    "used_segments = new_sampler._load_used_segments()\n",
    "\n",
    "\n",
    "def available_segments(sampler):\n",
    "    all_segments = sampler._load_all_segments_with_book_meta()\n",
    "    return [s for s in all_segments if s[\"segment_id\"] not in used_segments]\n",
    "\n",
    "\n",
    "available_new = available_segments(new_sampler)\n",
    "available_old = available_segments(old_sampler)\n",
    "print(f\"Available new segments: {len(available_new)}\")\n",
    "print(f\"Available old segments: {len(available_old)}\")\n",
    "\n",
    "# Genres present in either set\n",
    "genres = sorted({s[\"genre\"] for s in available_new + available_old})\n",
    "target_total = min(N_PREF, len(available_new) + len(available_old))\n",
    "per_genre = max(1, target_total // len(genres))\n",
    "print(\n",
    "    f\"Target total: {target_total} | Genres: {len(genres)} | Per-genre target: {per_genre}\"\n",
    ")\n",
    "\n",
    "samples = []\n",
    "chosen_ids = set()\n",
    "\n",
    "\n",
    "def sample_from_pool(pool, needed, max_per_book):\n",
    "    # Group by book, enforce per-book limit then randomly sample up to needed\n",
    "    by_book = defaultdict(list)\n",
    "    for seg in pool:\n",
    "        by_book[seg[\"book_id\"]].append(seg)\n",
    "    candidate_segments = []\n",
    "    for book_segs in by_book.values():\n",
    "        take = min(max_per_book, len(book_segs))\n",
    "        candidate_segments.extend(new_sampler._rng.sample(book_segs, take))\n",
    "    if len(candidate_segments) <= needed:\n",
    "        return candidate_segments\n",
    "    return new_sampler._rng.sample(candidate_segments, needed)\n",
    "\n",
    "\n",
    "for genre in genres:\n",
    "    # New first\n",
    "    new_pool = [\n",
    "        s\n",
    "        for s in available_new\n",
    "        if s[\"genre\"] == genre and s[\"segment_id\"] not in chosen_ids\n",
    "    ]\n",
    "    take_new = min(per_genre, len(new_pool))\n",
    "    picked_new = sample_from_pool(new_pool, take_new, MAX_PER_BOOK_PREF)\n",
    "    for s in picked_new:\n",
    "        chosen_ids.add(s[\"segment_id\"])\n",
    "    samples.extend(picked_new)\n",
    "\n",
    "    remaining_needed = per_genre - len(picked_new)\n",
    "    if remaining_needed > 0:\n",
    "        old_pool = [\n",
    "            s\n",
    "            for s in available_old\n",
    "            if s[\"genre\"] == genre and s[\"segment_id\"] not in chosen_ids\n",
    "        ]\n",
    "        take_old = min(remaining_needed, len(old_pool))\n",
    "        picked_old = sample_from_pool(old_pool, take_old, MAX_PER_BOOK_PREF)\n",
    "        for s in picked_old:\n",
    "            chosen_ids.add(s[\"segment_id\"])\n",
    "        samples.extend(picked_old)\n",
    "        if len(picked_old) < remaining_needed:\n",
    "            print(\n",
    "                f\"  {genre}: shortage (needed {per_genre}, got {len(picked_new) + len(picked_old)})\"\n",
    "            )\n",
    "\n",
    "# Fill remaining slots from any available (prefer new still)\n",
    "if len(samples) < target_total:\n",
    "    remaining_slots = target_total - len(samples)\n",
    "    remaining_new = [s for s in available_new if s[\"segment_id\"] not in chosen_ids]\n",
    "    remaining_old = [s for s in available_old if s[\"segment_id\"] not in chosen_ids]\n",
    "    # Try new first\n",
    "    add_new = min(remaining_slots, len(remaining_new))\n",
    "    if add_new:\n",
    "        samples.extend(new_sampler._rng.sample(remaining_new, add_new))\n",
    "        chosen_ids.update(s[\"segment_id\"] for s in samples[-add_new:])\n",
    "    remaining_slots -= add_new\n",
    "    if remaining_slots > 0 and remaining_old:\n",
    "        add_old = min(remaining_slots, len(remaining_old))\n",
    "        samples.extend(old_sampler._rng.sample(remaining_old, add_old))\n",
    "        chosen_ids.update(s[\"segment_id\"] for s in samples[-add_old:])\n",
    "\n",
    "new_sampler._rng.shuffle(samples)\n",
    "\n",
    "# Save\n",
    "output_file = TO_ANNOTATE_DIR / f\"{BATCH_NAME_PREF}.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(samples, f, indent=2)\n",
    "print(f\"Saved {len(samples)} segments to {output_file}\")\n",
    "\n",
    "# Stats\n",
    "new_count = sum(1 for s in samples if s[\"book_slug\"] in only_new_books)\n",
    "old_count = len(samples) - new_count\n",
    "print(f\"Sample composition -> New: {new_count} | Old: {old_count}\")\n",
    "by_genre_sample = defaultdict(int)\n",
    "for s in samples:\n",
    "    by_genre_sample[s[\"genre\"]] += 1\n",
    "print(\"By genre (sampled):\")\n",
    "for g, c in sorted(by_genre_sample.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {g}: {c}\")\n",
    "\n",
    "print(\"Preferential sampling done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67724a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split batch_002 into two halves for annotation\n",
    "BATCH_FILE = TO_ANNOTATE_DIR / \"batch_002.json\"\n",
    "with open(BATCH_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_samples = json.load(f)\n",
    "\n",
    "midpoint = len(all_samples) // 2\n",
    "batch_002_a = all_samples[:midpoint]\n",
    "batch_002_b = all_samples[midpoint:]\n",
    "with open(TO_ANNOTATE_DIR / \"batch_002_m.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(batch_002_a, f, indent=2)\n",
    "with open(TO_ANNOTATE_DIR / \"batch_002_v.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(batch_002_b, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
