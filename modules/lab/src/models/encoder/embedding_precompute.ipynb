{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0074ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/Projects/vis-desc/modules/lab/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "from utils import DATA_DIR\n",
    "\n",
    "ds_large = pd.read_parquet(DATA_DIR / \"datasets\" / \"large\" / \"combined.parquet\")\n",
    "\n",
    "# Split at 399 segments\n",
    "# sm_train, sm_test = train_test_split(ds_small, test_size=0.4, random_state=SEED)\n",
    "# pd.DataFrame(sm_train).to_parquet(\n",
    "#     DATA_DIR / \"datasets\" / \"small\" / \"train.parquet\", index=True\n",
    "# )\n",
    "# pd.DataFrame(sm_test).to_parquet(\n",
    "#     DATA_DIR / \"datasets\" / \"small\" / \"test.parquet\", index=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e19f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split at 500 segments\n",
    "ds_small = pd.read_parquet(DATA_DIR / \"datasets\" / \"small\" / \"agreed.parquet\")\n",
    "# sm_train = pd.read_parquet(DATA_DIR / \"datasets\" / \"small\" / \"train.parquet\")\n",
    "# sm_test = pd.read_parquet(DATA_DIR / \"datasets\" / \"small\" / \"test.parquet\")\n",
    "\n",
    "# # Exclude old train and test from agreed (key by text)\n",
    "# ds_small = ds_small[\n",
    "#     ~ds_small[\"text\"].isin(sm_train[\"text\"])\n",
    "#     & ~ds_small[\"text\"].isin(sm_test[\"text\"])\n",
    "# ]\n",
    "# print(len(ds_small))\n",
    "\n",
    "# sm_train2, sm_test2 = train_test_split(ds_small, test_size=0.4, random_state=SEED)\n",
    "# sm_train2 = pd.concat([sm_train, sm_train2])\n",
    "# sm_test2 = pd.concat([sm_test, sm_test2])\n",
    "\n",
    "# # Put last row from test2 to train2 to keep 300:200 ratio\n",
    "# sm_train2 = pd.concat([sm_train2, sm_test2.iloc[[-1]]])\n",
    "# sm_test2 = sm_test2.iloc[:-1]\n",
    "\n",
    "# sm_train2.to_parquet(\n",
    "#     DATA_DIR / \"datasets\" / \"small\" / \"train2.parquet\", index=True\n",
    "# )\n",
    "# sm_test2.to_parquet(\n",
    "#     DATA_DIR / \"datasets\" / \"small\" / \"test2.parquet\", index=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1080eb2",
   "metadata": {},
   "source": [
    "### ModernBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c12f6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-25 23:50:25.402142: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761429025.499564  963635 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761429025.528790  963635 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-25 23:50:25.830611: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 58720.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from text2features import FeatureService\n",
    "from text2features_paths import (\n",
    "    FEATURE_PIPELINE_RESOURCES,\n",
    "    FEATURE_SERVICE_MODERNBERT_ONNX_PATH,\n",
    ")\n",
    "from sklearn.utils import gen_batches\n",
    "\n",
    "feature_service = FeatureService(\n",
    "    feature_pipeline_resources=FEATURE_PIPELINE_RESOURCES,\n",
    "    modernbert_onnx_path=FEATURE_SERVICE_MODERNBERT_ONNX_PATH,\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96003714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 11it [04:53, 22.42s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "batches = gen_batches(len(ds_small), BATCH_SIZE)\n",
    "embedding_series = []\n",
    "\n",
    "for batch in tqdm(batches, desc=\"Extracting embeddings\"):\n",
    "    texts = ds_small[\"text\"].iloc[batch].tolist()\n",
    "    features = feature_service.get_modernbert_embeddings(texts)\n",
    "    embedding_series.extend(features)\n",
    "\n",
    "embedding_df = ds_small[[\"text\"]].copy()\n",
    "embedding_df[\"cls\"] = embedding_series\n",
    "embedding_df.to_parquet(\n",
    "    DATA_DIR / \"datasets\" / \"small\" / \"modernbert_cls_embeddings.parquet\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2fb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 1563it [11:18:16, 26.04s/it]\n"
     ]
    }
   ],
   "source": [
    "batches = gen_batches(len(ds_large), BATCH_SIZE)\n",
    "embedding_series = []\n",
    "\n",
    "for batch in tqdm(batches, desc=\"Extracting embeddings\"):\n",
    "    texts = ds_large[\"text\"].iloc[batch].tolist()\n",
    "    features = feature_service.get_modernbert_embeddings(texts)\n",
    "    embedding_series.extend(features)\n",
    "\n",
    "embedding_df = ds_large[[\"text\"]].copy()\n",
    "embedding_df[\"cls\"] = embedding_series\n",
    "embedding_df.to_parquet(\n",
    "    DATA_DIR / \"datasets\" / \"large\" / \"modernbert_cls_embeddings.parquet\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79749009",
   "metadata": {},
   "source": [
    "### MiniLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055fc0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-25 19:50:31.030267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761414631.082866  788025 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761414631.113630  788025 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-25 19:50:31.212796: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e147954",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = ds_small[[\"text\"]].copy()\n",
    "embedding_df[\"cls\"] = model.encode(ds_small[\"text\"].tolist()).tolist()\n",
    "embedding_df.to_parquet(\n",
    "    DATA_DIR / \"datasets\" / \"small\" / \"minilm_embeddings.parquet\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = ds_large[[\"text\"]].copy()\n",
    "embedding_df[\"cls\"] = model.encode(ds_large[\"text\"].tolist()).tolist()\n",
    "embedding_df.to_parquet(\n",
    "    DATA_DIR / \"datasets\" / \"large\" / \"minilm_embeddings.parquet\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6d706",
   "metadata": {},
   "source": [
    "### Validate saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae5e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "from utils import DATA_DIR\n",
    "\n",
    "sm_minilm = pd.read_parquet(\n",
    "    DATA_DIR / \"datasets\" / \"small\" / \"minilm_embeddings.parquet\"\n",
    ")\n",
    "lg_minilm = pd.read_parquet(\n",
    "    DATA_DIR / \"datasets\" / \"large\" / \"minilm_embeddings.parquet\"\n",
    ")\n",
    "sm_modernbert = pd.read_parquet(\n",
    "    DATA_DIR / \"datasets\" / \"small\" / \"modernbert_cls_embeddings.parquet\"\n",
    ")\n",
    "lg_modernbert = pd.read_parquet(\n",
    "    DATA_DIR / \"datasets\" / \"large\" / \"modernbert_cls_embeddings.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b3393",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lg_minilm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# assert sm_minilm[\"cls\"].apply(tuple).nunique() == SM_LENGTH\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# assert lg_minilm[\"text\"].nunique() == LG_LENGTH\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# assert lg_minilm['cls'].apply(tuple).nunique() == LG_LENGTH\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# NaNs in 'cls' lists\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sm_minilm.explode(\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].isna().any()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mlg_minilm\u001b[49m.explode(\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].isna().any()\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sm_modernbert.explode(\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].isna().any()\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lg_modernbert.explode(\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].isna().any()\n",
      "\u001b[31mNameError\u001b[39m: name 'lg_minilm' is not defined"
     ]
    }
   ],
   "source": [
    "SM_LENGTH = 500\n",
    "LG_LENGTH = 100000\n",
    "\n",
    "assert len(sm_minilm) == SM_LENGTH, f\"{len(sm_minilm)} != {SM_LENGTH}\"\n",
    "assert len(lg_minilm) == LG_LENGTH, f\"{len(lg_minilm)} != {LG_LENGTH}\"\n",
    "assert len(sm_modernbert) == SM_LENGTH, f\"{len(sm_modernbert)} != {SM_LENGTH}\"\n",
    "assert len(lg_modernbert) == LG_LENGTH, f\"{len(lg_modernbert)} != {LG_LENGTH}\"\n",
    "\n",
    "# Duplicates in 'text' column\n",
    "assert sm_minilm[\"text\"].nunique() == SM_LENGTH\n",
    "assert sm_minilm[\"cls\"].apply(tuple).nunique() == SM_LENGTH\n",
    "assert lg_minilm[\"text\"].nunique() == LG_LENGTH\n",
    "assert lg_minilm[\"cls\"].apply(tuple).nunique() == LG_LENGTH\n",
    "assert sm_modernbert[\"text\"].nunique() == SM_LENGTH\n",
    "assert sm_modernbert[\"cls\"].apply(tuple).nunique() == SM_LENGTH\n",
    "assert lg_modernbert[\"text\"].nunique() == LG_LENGTH\n",
    "assert lg_modernbert[\"cls\"].apply(tuple).nunique() == LG_LENGTH\n",
    "\n",
    "# NaNs in 'cls' lists\n",
    "assert not sm_minilm.explode(\"cls\")[\"cls\"].isna().any()\n",
    "assert not lg_minilm.explode(\"cls\")[\"cls\"].isna().any()\n",
    "assert not sm_modernbert.explode(\"cls\")[\"cls\"].isna().any()\n",
    "assert not lg_modernbert.explode(\"cls\")[\"cls\"].isna().any()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
